\documentclass[twoside,letterpaper]{llncs}
% \documentclass[twoside,letterpaper]{sig-alternate}

\usepackage{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{eurosym}
\usepackage{tikz}
%\usepackage{listings}
%\usepackage{graphicx}
%\usepackage{wrapfig}
%\usepackage{caption}
%\usepackage{subcaption}

\usetikzlibrary{cd}
%\usetikzlibrary{shapes,arrows}
%\usetikzlibrary{positioning}
%\usetikzlibrary{calc}

\def\mathperiod{.}

\def\mathcomma{}
\def\mathperiod{}


\title{Xolotl}
\subtitle{A request-and-forward mixnet format with selective statefulness for forward secure and post-quantum anonymity}
\author{Jeffrey Burdges \and Christian Grothoff}
\date{\today}
\institute{Inria}

\begin{document}
\maketitle

% \section{}

% L\'aszl\'o Baba's quasi-polynomial time algorithm for graph isomorphism\cite{Babai-GI}

\begin{abstract}
We describe a new double ratchet construction Xolotl, inspired by the
Axolotl ratchet, that integrates with the Sphinx mix network packet
format.  We argue this opens the door to compact mix network formats
with stronger forward secrecy and truly hybrid anonymity, meaning they
rest upon the stronger of the security assumptions required by the
different public key primitives employed.

We also describe an onion encrypted ``log'' that allows messages to
be routed by several single-use reply blocks (SURBs) before being
unwrapped by the receiver.  This gives us a request-and-forward
architecture with privacy for both the sender and recipient,
increases reliability, and simplifies several protocol enhancements.
\end{abstract}


\section{Introduction}

Anonymity systems based on ``onion routing''~\cite{SS03} like Tor or
I2P are known to be vulnerable to correlation attacks by a passive
adversary who can observe both endpoints of a
circuit~\cite{timing-fc2004}, such as a national ISP.  Any attempt to
defeat correlation attacks must take latency into consideration.
% TODO: cite https://blog.torproject.org/blog/one-cell-enough

There are several recent proposals like~\cite{Alpenhorn}
and~\cite{Dissent} that avoid introducing much latency by instead
introducing vast amounts of cover traffic.  There are several issues
with this trade off:  

First, if users can tolerate latency comfortably then they should
use a protocol that does so.  An adversary can extract metadata not
only from timing the protocol but from timing side channels, even
user behavior.  Also there is likely a synergy between anonymity from
latency and cover traffic \cite{??}.

Second, a protocol that scales poorly might favor powerful
organizations with fixed established anonymity sets, such as hiding
which executive at a company asked managers to violate some law.
Instead, we should favor users' whose anonymity needs naturally
cross organizational boundaries, like volunteer organizations,
journalists' sources, whistleblowers, protest organizers, etc.

We favor the opposite trade off in which we accept higher latency but
avoid introducing excessive cover traffic. In effect, we propose to
sacrifice use cases that require low latency like voice, while
offering an inexpensive privacy tool that defeats correlation attacks.
Our target domain includes most text messaging applications and
e-mail, but excludes large file transfers.

\subsection{Messaging API goals} 
% COMMENT: This seems more line API goles than network architecture

A central goal for our network architecture is that messaging is 
{\bf asynchronous} and must work reliably even if sender and receiver
are never online at the same time.  As a result, we ask that messages
can be stored for days to months at nodes in the network.  Generally,
the receiver will select a set of nodes to store his messages and
select a replication level to achieve the desired level of
reliability. While the number of replicas can be disclosed to the
sender, the specific set of replicas is only known to the receiver.
Replicas also do not know of each other, and even collaborating
replicas must not be able to detect that they are storing the same
message for the same receiver.

We assume that the sender initially has a way to securely resolve the
recipient's address to a set of sender-specific single-use reply
blocks (SURBs), for example using an out-of-band exchange or using
name resolution in the GNU Name System~\cite{gns} using a private
label.  However, once a set of SURBs has been established between
sender and receiver, the protocol must maintain the connection
indefinitely, or at least as long as neither sender nor receiver fail
to be online for weeks or months at a time.  Naturally, either side
can also choose to sever the link at any time.
% TODO: SURBs expire too fast for this.  We need semi-public contact
% points.  GNS would leak metadata if used for this.  So I think 
% ``mailbox gatway points'' do this better.

For path selection, sender and receiver require the ability to select
``random'' nodes for routing.  We assume that the network offers a
Byzantine fault-tolerant random peer sampling mechanism, for example
using trusted directory servers~\cite{tordir} or using fault-tolerant
random peer sampling protocols, such as BRAHMS~\cite{brahms}.  Our
design allows peers to in principle impose further constraints on the
path selection, for example limiting the set of guard
nodes~\cite{oneguardisenough}, biasing the selection in favor of
higher bandwidth routers~\cite{findexample} or selecting nodes for
persistent replication based on advertised storage capabilities.
While those choices do matter for privacy, we consider them orthogonal
and thus outside of the scope of this work.
% Discuss: I suspect peer sampling could be biased for an epistemic
% attack on users, so this line sounds like on-going research at
% present.  We do need to sort it out thought so I'm leaving this
% right now.

\subsection{Cryptographic challenges}

We desire anonymity properties that improve on Tor in all respects,
provided our system can achieve similar usage to Tor.  In this vein,
we want cryptographic properties that seems equivalently strong as well.
% I donno if I like this "competitive" framing. 
% Should we mention that Tor might gain post-quantum?

Low latency anonymity tools like Tor achieve {\em forward secrecy}
by employing an ephemeral key exchange on both servers and clients.
We face a cryptographic inconvenience that high latency schemes
like mix networks must ask clients to encrypt to the long term keys
of mix nodes, meaning they lack conventional {\em forward secrecy}.  

There is a superficial similarity between forward secrecy and
post-quantum cryptography: As post-quantum public key primitives
remain young, post-quantum protocols should be analyzed in a hybrid
setting where even ephemeral keys might be compromised.  In other
words, there is a chance that either the classical elliptic curve key
exchange or the post-quantum key exchange might be compromised, but
the chance of both being broken is judged lower.  We therefore wish
to produce a scheme that combines the strengths of both classic and
post-quantum primitives.  However, there are technical obstacles to
deploying a post-quantum key exchange in a mix network, starting with
the simple problem that messages tend to be larger
and computations more expensive.

In this article, we propose Xolotl, a stateful ``ratchet'' based
solution, inspired by the Axolotl ratchet~\cite{TextSecure}, that
extends the Sphinx mix net packet format~\cite{Sphinx}.  
Xolotl provides limited post-quantum protections and forward secrecy
in exchange for leaking some limited correlating information and
increased path length.  

Although harmful, this leakage, and ratchet storage costs, provide an
important parameter for mix network architects:  In any mix network,
mix node key lifetimes correspond with SURB lifetimes, so anytime
contacts do not communicate during a key epoch they must reestablish
connection through a slightly riskier channel.  We believe Xolotl
provides the flexibility needed to extend SURB lifetimes without
making mix node keys too juicy of a target for adversaries.
% George Danezis' fs-mixes~\cite{fs-mix}, or perhaps punctured encryption.


\section{Extending Sphinx}

We start with a setup consisting of a Sphinx-based mix network in
which each mix node has a medium term routing key $X = x G$ with a
predefined validity period, and a medium term name that identifies
both it and $X$.  We expect this name would be derived from the
signature of a longer term signing key on $X$ and its validity period.

For simplicity, we assume all nodes in the network are aware of the
medium term routing keys $X$ and validity periods for all other nodes.
Furthermore, public keys for future periods are expected to be
securely distributed ahead of time, possibly months before they are
used.


\subsection{Sphinx background}

We provide a rough outline of the Sphinx mix net packet format from 
\cite{Sphinx}, adapted to transport SURBs for use at a cross over point
to provide simultaneous anonymity for both senders and receivers.
For further background, we refer the reader to the Sphinx construction
in \cite{Sphinx} and the securityproof that inspired it~\cite{FormalOnion},
as well as wide block ciphers~\cite{Lionness}.

\begin{figure}
  \begin{center}
     FIXME: include graphic. Or maybe make new one with $\epsilon$?
  \end{center}
  \caption{The Sphinx packet format (reproduced from~\cite{Sphinx}).}
  \label{fig:sphinx}
\end{figure}

A Sphinx packet (Figure~\ref{fig:sphinx}) flows along a client-selected
route $X_1,\ldots,X_n$ where $n$ is less than some small network defined
constant.  A Sphinx packet consists of an elliptic curve point $\alpha$,
a routing header $\beta$ of a fixed length $L$, a single-use reply block
(SURB) field $\epsilon$ also of length $L$, a MAC $\gamma$ that
authenticates the contents of $\beta$ and $\epsilon$, and a body $\delta$.
All of $\beta$, $\delta$, and $\epsilon$ are onion encrypted, but $\beta$
and $\epsilon$ use a stream cipher, while $\delta$ uses a wide block
cipher since it is not authenticated.

% FIXME: epsilon is a new thing, not in original Sphinx, right?
% (Don't have the paper here, its' not in the diagram...).
% If it is not in the paper, we need to point out where this
% part comes from (or if it is new).
% Yes, we should look up a citation eventually.

Each hop $X$ processes $(\alpha,\beta,\gamma,\delta,\epsilon)$
as follows.  First, it computes a shared secret $s = x \alpha$ to
derive a replay code, a MAC key, a stream cipher key, 
 a blinding key $b$, and a wide block cipher key. 
It uses the MAC key to check the MAC of $\beta$ and $\epsilon$ and
 then checks its database for the replay code.
It aborts and drops the packet if either the MAC check fails or
 if the replay code is present.  Otherwise it adds the replay code
 to its database.
Next, it pads $\beta$ with $l$ zeros and decrypts the result
 using the stream cipher to produce a $\hat\beta$.
An initial segment of $\hat\beta$ of length $l' < l$ must contain
a valid routing command.  

We discuss some new routing commands in this paper, but the typical
routing command states the next hop $N'$ to which to forward the
packet, and the $\gamma'$ the next hop $N'$ requires. 
In this case, our hop $N$ computes $\alpha' := b \alpha$,
extracts $\beta' := \hat\beta[l'..L+l']$,
decrypts $\delta$ using the wide block cipher
 to produce $\delta'$, and
decrypts $\epsilon$ using more of the stream cipher
 to produce $\epsilon'$.
Now the packet $(\alpha',\beta',\gamma',\delta',\epsilon')$ is
forwarded to $N'$,
 according to whatever mixing rules the protocol specifies.


\subsection{Cross over points}

% FIXME: needs a diagram ;-).

A classical mix node command tells the mix to act as a ``cross over''
point by activating our SURB $\epsilon$ to give routing control to
the message's recipient.  The path up to the cross over point
is selected by the sender and protects the privacy of the sender,
while the path from the cross over point on is selected by the
receiver and protects the receiver.  Only the cross over point
itself is disclosed in the clear to the sender.

A cross over command provides a new
 $\alpha''$ and $\gamma''$ that replace our old ones.  
In addition, $\delta$ is replaced by the decrypted $\delta'$, 
$\beta$ is replaced by $\epsilon'$, and $\epsilon$ itself is zeroed.
Now the mix reruns the Sphinx decoding process on the new packet
$(\alpha'',\epsilon',\gamma'',\delta',0\cdots0)$.  
After this second run there is nothing about the packet that 
identifies it --- not even to the original sender.
We must zero the $\epsilon$ field so that the recipient can compute
the required MACs without encoding additional information. 

As stated, our recipient has chosen the cross over point $X$,
supplied the sender with $(X,\alpha'',\epsilon',\gamma'')$,
and the sender built a route to $X$.  This reduces the sender's
maximum route length by roughly 2.5 hops, assuming an $\alpha$
is twice as long as an $X$.  There is never any reason to encode
$\alpha''$ and $\gamma''$ into $\epsilon'$ because doing so would
$\epsilon$ longer for every packet, even when $\epsilon$ is unused
because the packet does not traverse another cross over point.
Instead we should simply make $\epsilon'$ shorter than the length
$L$ of $\beta$ by zero padding $\epsilon'$ when we insert it into
the $\beta$ slot at the cross over point.
$$ \beta'' := \epsilon' \,||\, 0\cdots0 $$
% TODO: This is the only occurance of $\beta''$

We could similarly increase the total route length by one if
we added a next hop $X'$ to the cross over command, built an
$\epsilon''$ using a stream cipher and sent
 $(\alpha'',\epsilon',\gamma'',\delta',\epsilon'')$ to $X''$.
We consider this is wasteful because hops cost vastly more than
a few bytes in the header.
% FIXME: I do not understand :-(.  But, what I wonder is
% why we throw away all of \beta, instead of requiring
% the sender to compute \beta in such a way that some
% bytes (L - hops-spent) to match the new
% \beta''; that might allow us to reduce \epsilon further...

Worse, we observe that $\delta'$ has been stripped of all onion
encryption layers created by the sender because the sender must not
know anything about the packet after the cross over point,
 including wide block cipher keys.
We therefore forbid $\delta'$ from being the plaintext message itself
and insist that it be protected with another layer of end-to-end
encryption.  Indeed, this end-to-end encryption layer must use
different ephemeral keys to prevent cross over points from performing
correlation attacks on $\delta'$.

If all SURBs are supplied to the sender by the recipient, then
we could simply provide an extra wide block cipher key with which
the sender pre-encrypts $\delta$ before applying its own onion layers.
We do assume this because SURBs have a limited lifespan.  
If the sender does not posses any SURBs, then they could contact the
recipient through a public access point, and ask for SURB. 
These public access points would act like cross over points, except
that they would supply the SURB themselves from a stash supplied by
the recipient.

In this unusual scenario, it impacts our mix networks' security
less if $\delta'$ is only ever seen by the cross over point, thereby
simplifying our overall design.   In particular, we might not mind
if the cross over point observes an ephemeral elliptic curve point
in $\delta'$, but even tools like Elligator~\cite{elligator} do not
conceal this point from a second hop.

In short, if we added this second hop $X''$ to lengthen the route
then $X''$ might discover its position as the hop after a cross over
point.  We could have a more oblivious hop at the cost of adding a
few bytes to the header.

\subsection{Aggregation points}

As mentioned in the introduction, we must never assume that users,
nor any agent they control, is reliably online.  
% ``It's an asynchronous world.''
% https://github.com/WhisperSystems/Signal-Android/blob/master/CONTRIBUTING.md
As a consequence, we must retain messages for an offline recipient
until their client requests delivery.  
At present, there are no successful secure messaging protocols
without this IMAP/POP-like {\em request-and-forward} functionality,
except arguably off-the-record messaging. 

We expect this necessitates that messages destined for the same
recipient flow into mailboxes at a small number aggregation points
that process delivery requests.  These aggregation points should
learn as little as possible about recipients or senders, but the
recipient should learn the sender's identity from the protocol.
In~\cite{agl-pond-hmac}, Adam Langely explains that Pond has similar
requirements and indicates important advantages of delivery tokens
over more complex schemes, like group signatures~\cite{VLR,BBS}.

We can easily add a ``deliver to mailbox'' command to Sphinx so that
SURBS can act as a delivery token.  In fact, SURBs provide near
perfect delivery properties in sense of~\cite{warner-delivery}.
An aggregation point cannot learn the sender's identity, unless
colluding with the cross over point and all the mixes in the 
sender's route to the cross over point.  
In fact, even the receiver cannot learn more by colluding with
the aggregation and cross over points.  In addition, our SURB
hides both the aggregation points and the mailbox from the sender,
which simplifies the recipient's task if they change aggregation
points and mailbox identifiers.

However, we must address a hiccup in how SURBs identify themselves
and senders.

\subsection{Unwinding SURB onion layers}

We noted that a cross over point sees the body, denoted $\delta'$
above, without any wide block cipher encryption layers.  We have
chosen our wide block cipher so that its encryption and decryption
operations provide exactly the same security guarantees and can
safely be swapped.  This conceptual swap happens at our cross over
point so that subsequent hops do not recognize themselves as being
after a cross over point.  They happily apply the decryption
operation without realizing that it further encrypts the body.
However, our recipient must somehow {\bf unwind} these layers of
onion encryption, and to do so efficiently the recipient must have
a way to identify which of its SURBs was used, so that they
can select the correct set of keys.

There are two basic schemes for obtaining the key material to
unwind the encryption applied to $\delta$ from mixes encrypting
during the SURB hops:

\begin{enumerate}
 \item The recipient may {\em record} the wide block cipher keys used
   under a {\it SURB name} $\eta$ derived from the shared secret $s$.
   This approach has the advantage that it requires no additional
   space in the header and provides simple authentication for arriving
   SURBs.

 \item Alternatively, our recipient could construct their SURB using a
   {\em seed} that they also encode into the ``bottom'' of the SURB
   itself, so that they may {\em reconstruct} the original SURB and
   keys.  Encoding a seed provides advantages in multi-device
   scenarios where all devices of a user can decrypt messages without
   further communication after sharing some initial key material.
   However, to reconstruct the SURB from a seed in an evolving mix
   network does require recipients to record their past knowledge of
   the mix network, which may eliminate the advantage in multi-device
   scenarios in cases where peers do not always share the same global
   view.
\end{enumerate}

In either scenario, our packet takes a predetermined route to the
recipient who unwinds $n$ encryptions using information present on
their disk and either $s$ or their $\beta'$.  Mixes delay
messages along this route, but so far our recipient cannot change
the route. 

\subsection{Redirecting messages}

We want SURB to be used to reach the aggregation point because
this gives us good delivery properties.  We also require the
aggregation point not learn anything about either the user, or
the SURB used to reach the aggregation point

In principle, recipients could simply send the aggregation point
a packet with a flush mailbox command that launched all pending
packets along whatever remained of their route.  We foresee many
difficulties with such an approach, including simple route length
constraints and packet loss due to network churn, mix node key
lifetime, and clients changing guard nodes, any of which can cause
paths used in SURBs to become unavailable.

Instead, we propose that SURB directed messages should arrive at
an aggregation point as the final destination as far as the SURB
is concerned. The aggregation point then stores  the incoming SURB's
name $\eta$ derived from $s$ and $\delta'$.
This should even be done if the aggregation point is the ultimate
recipient, for example if the user is logged out and thus the
secret keys for decryption might be unavailable.  
% Discuss: I'm not do sure about this part : 
 % This way, the user's desktop may also act as just another
 % aggregation point if the user then chooses to access his messages
 % from a mobile device.

Thus, we need a method for our final recipient to retrieve
$\delta'$ and the corresponding SURB name from the aggregation point.


\subsection{SURB logs}

We do not consider private information retrieval (PIR)
schemes~\cite{pir} because they increase complexity, invoke disparate
security properties, leak metadata through excessive bandwidth, and do
not support message deletion.
% FIXME: citations needed...

There is no way to ``squeeze'' our incoming SURB name $\eta_0$ into
the body $\delta$ because the body was previously encrypted with a
wide block cipher and thus cannot be shrunk.

Our recipient could ask the aggregation point to report the waiting
messages, and then send it separate SURBs assigned to each reported
SURB name, but this requires an extra round trip in a protocol with
notable latency. 

Instead, we propose adding a {\it SURB log} $\zeta$ to the header.
Any regular Sphinx hop encrypts $\zeta$ with more of the stream
cipher, but does not include it when verifying the MAC $\gamma$.
An aggregation point that receives fresh SURBs for a nonempty
mailbox simply places the previous SURB name $\eta_0$ into $\zeta$,
places $\delta'$ into the body, and populates the remaining fields
as usual.

For our recipient, there is an incoming SURB name $\eta_1$ that 
controls unwinding back to the state seen by the aggregation point.
We unwind $\zeta$ as well so that our recipient learns $\eta_0$ too,
and may continue unwinding back to the cross over point.
% FIXME: Pictures, please!

We do not MAC $\zeta$, so any adversary can flip bits arbitrarily
there.  As $\eta$ is random, if it is large enough then random
collisions should be impossible, but an aggregation point sees
well-formed $\zeta$.  An aggregation point could therefore identify
a message as coming form an incorrect original sender.

For this reason, one should consider the mix network's sender
identification as an unauthenticated hint that simplifies proper
authentication in the body, say by supporting Axolotl header
encryption.  

We weakly authenticate the $\eta_0$ extracted from $\zeta$,
as being supplied by the aggregation point, because only the client
knows $\eta_1$ and all the layers of encryption applied to $\eta_0$.  
We imagine this weak authentication may help identify the source of
unwanted messages, or a denial of service attack, say by a malicious
public access point.

\subsection{Deletion policy}

To maximize the chance of delivery and to possibly support the user
accessing their messages from multiple devices, aggregation points
should not delete messages until they either need to reclaim the
storage space or are explicitly told to do so by the recipient.
However, aggregation points should be careful to avoid wasting two
SURBs from the same batch on the same message.  A message delivering a
subsequent batch can then request their deletion to avoid re-delivery.


\subsection{Unwinding guards and repeated retargeting}

... back to an aggregation point ...

In Tor, clients rotate circuits every 10 minutes, while holding
fixed their first hop, called a guard node.  This protects clients
from attackers seeking to push them onto a malicious guard
node~\cite{tor-guards}.

% FIXME: discussion below is a bit confusing, needs editing.
In a mix network, there are reasons clients might concentrate their
traffic through a few guard nodes, like batching messages to hide
message count, or saving battery on a mobile device, as notification
servers do currently.  At the same time, an aggregation point could
hoard a user's messages until the user selects a malicious guard,
so users may wish to avoid rotating guards too much.




As a result, any recipient's guard node become a de-facto aggregation
point, except that the SURB would contain instructions for another hop
to be taken.  If a user does change the guard, then SURBs used to poll
messages from aggregation points may leave messages left waiting at
the old guard, and this may be common due to the mix network's
high latency.

We noted that aggregation points also need not delete messages until
told to do so.  Yet, we also envision conversing clients achieving
lower latency by sharing SURBs that arrive directly without passing
through long-term storage aggregation points.  Any such messages could
more easily be left waiting at an old guard.

We can pick these messages up using the same technique of extending
unwinding with the SURB log $\zeta$ as with aggregation points.  In
fact, to allow repeated retargeting we allow multiple SURB names in
$\zeta$, shift $\zeta$ rightward when adding a SURB name $\eta$, and
shift $\zeta$ leftward when extracting a SURB name during unwinding.

% FIXME: Pictures, please! Especially for the iterative retargeting!
% Having a picture of the complete package format with the
% multi-\eta \zeta in a network diagram that shows an old
% guard, a new guard, a crossover and at least one (storage)
% aggregator (not in this order ;)) would be good.


\section{Key compromises and forward secrecy}

We have observed that high latency anonymity schemes depends upon
nodes using non-ephemeral key material, thus opening them to key
compromise attacks that do not impact onion routers like Tor.
There are several natural ways one might harden mix networks against
node keys being compromised. 

\subsection{Key rotation and replay attacks}

As a rule, mix networks must prevent replay attacks, normally using
a database of some form.  As this database must not grow indefinitely,
mix nodes must rotate their keys periodically.  These keys should be
destroyed when no longer used to provide a measure of forward security.

In principle, we could rotate keys quickly so that the compromise
window for each key stays short.  However, we also must
support single-use reply blocks (SURBs) so that anonymous users can
receive messages.  As SURBs are built to a specific set of node
keys they cannot outlive the key rotation schedule.  This creates
a tension between forward security and usability.

We could rotate node keys slow enough for our usability goals, but add
a faster rotating identity-based epoch key issued by a collective of
trusted nodes, and deform the SURB's key material to account for this
rotating identity-based epoch key.
% FIXME: citation needed (I assume somebody published this atrocity?)
This buys use forward security
assuming at least some trusted node does not get compromised, but
would be difficult to deploy in practice. 

We could use punctured encryption~\cite{libforwardsec} for our
mix nodes key, so that mix nodes who correctly puncture their key
after decrypting a message cannot decrypt the same message again. 
% TODO: Should I cite an older article on punctured encryption?
% TODO: Sure. For now we have no page limit ;-).
As a rule, punctured encryption schemes require $O(n)$ time for
decryption where $n$ is the number of punctures so far.  There are
techniques for epoch based puncturing that make $n$ far less than
the number of packets.  In a mix network, these would require
deforming the SURB as well. 

Any scheme for deforming SURBs requires a delicate proof of security
because several mix network packet formats based on malleable key
material were broken~\cite{Danezis2006}. 
Also, these ideas all require slower pairing-based cryptography that
would increase our mix node's vulnerability to denial of service attacks. 


\subsection{Post-quantum cryptography}

Along with the primitives being relatively young and poorly explored,
an important obstacle to deploying post-quantum cryptography is
the comparatively large key sizes.  As a comparison: 
%
A recent Ring-LWE key exchange New Hope~\cite[\S7, p.10]{NewHope} needs
 key sizes of 1824 or 2048 bytes, both of which must be ephemeral,
while one McEliece-like system McBits~\cite{McBits,InitRec}
 needs a staggering 1MB for public keys.
%
Super-singular isogeny Diffie-Hellman (SIDH)~\cite[p. 21]{SIDH-2016} keys
are only 564 bytes, or 751 bytes uncompressed, but
 the key exchange requires at least 100 times as much CPU time as
 an ECDH key exchange with equivalent classical security.

Anonymity tools like mix networks are sensitive to key size because 
users interact with numerous nodes and key material overhead is 
quadratic in the number of hops. % $n(n+1)/2$
% FIXME: Eh, what? How? Where? It is linear!!?!?!?!!

% FIXME: need to add a conclusion from this, i.e
% that we do not want to do PQC on every hop or
% for every message, but might be happy with
% setting up PQC-secured pairwise crypto with
% one designated hop on a path.

\subsection{Sphinx key blinding}

% FIXME: deduplicate with what we had above, most of it is duplicated
% and/or ought to have been said when we first talked about Sphinx.
% After that, this subsection can probably go away.

Sphinx~\cite{Sphinx} is a packet format for anonymizing mix networks
that is provably secure in the universal composability framework, and
 addresses the key material burden by mutating or reblinding a
 single ephemeral public key $\alpha$ with each hop,
 as opposed to unwrapping an unrelated public key for each hop.

In Sphinx, an elliptic curve point is blinded by multiplication with
a shared secret scalar derived from the Diffie-Hellman exchange using
the same point:
After selecting an initial private scalar $x_0$,
 public curve point $\alpha_0 = x_0 G$, and 
 a sequence of $n$ nodes with keys $Y_i = y_i G$,
we recursively define 
\[ \begin{aligned}
\textrm{shared secret}\quad
 s_i &:= x_i Y_i = y_i \alpha_i \mathcomma \\
\textrm{blinding factor}\quad
 b_i &:= H(s_i) \mathcomma \\
\textrm{next private key}\quad
 x_{i+1} &:= b_i x_i \mathcomma \\ % \quad\textrm{and} \\
\textrm{next public key}\quad
 \alpha_{i+1} &:= b_i \alpha_i \quad\textrm{for $i < n$.} \\
\end{aligned} \]
Our $i$th node replaces $\alpha_i$ by $\alpha_{i+1}$.


\subsection{Problems combining post-quantum cryptography and Sphinx}

We ask if any post-quantum public key exchanges admit 
a key blinding operation suitable for Sphinx. 
At present, the answer appears to be {\bf no}, for similar reasons to
why these primitives still lack convenient signature schemes. 
In particular, there are blinding operations but they incur significant
costs  that are asymptotic in the number of hops.

In SIDH, a public key is an isogeny whose kernel consists $p$-torsion
for $p=2$ or $3$.  It reveals guide points in the $5-p$-torsion but
must not reveal the image of any known $p$-torsion points.  
As a result, current attempts to blind SIDH keys for signature schemes
add another torsion prime beyond 2 or 3, increasing the size of the
base field.  In Sphinx, we could invent new shared $p$-torsion guide
points for blinding, thus avoiding
% FIXME: avoiding WHAT? correlation attacks?
because blinding happens after the key exchange
establishes confidentiality, but doing so requires building confidence
in this new cryptographic operation.  Worse, there are currently open
questions around key validation in SIDH that prevent using long term
keys~\cite{SIDH-NoValidation}, which Sphinx requires.

In Ring-LWE, there is enough flexibility for blinding constructions
that increase the key size, fully homomorphic encryption schemes that
avoid this increase, and even a primitive similar to universal
reencryption exists~\cite{963628}.  In all cases however, we still
increase key sizes dramatically over existing key exchanges and we face
difficult key wrap problems with the fully homomorphic encryption
schemes.

We consider such schemes currently unsuitable for another reason though: 

In Sphinx, there is no requirement that the blinding keys $b_i$ be
drawn from a uniform distribution because standard assumptions on
elliptic curves suitable for cryptography ask that an adversary has
no appreciable advantage in determining the correspondence between
$\alpha_i$ and $\alpha_{i+1}$ without knowing $b_i$.  
Indeed, the Curve25519 function commonly used for Diffie-Hellman key
exchange in Sphinx implementations goes so far as to set the high bit
of the private scalar as a protection against non-constant time
implementation.
% FIXME: there is a sentence missing here relating this back to
% RLWE, i.e saying that RLWE requires keys selected from uniform
% distribution. ``there are also'' here makes no sense.
% It is totally unclear what algorithms you are talking about!!!
There are also cryptographic algorithms like signatures for which
this assumption does not suffice and blinding scalars must be chosen
from a uniform distribution.

There are similar assumptions underlying both Ring-LWE and SIDH.
We believe they should be viewed as stronger than simply assuming the
security of the key exchange scheme itself, partially due to their
youth, but also because the underlying operations cannot so easily
yield a uniform distribution on public keys.  We believe further
research into signature schemes might help build our confidence in
blinding operation with Ring-LWE and SIDH, but this will take time.

As these schemes remain young, we want post-quantum public key
systems to be used in a hybrid protocol with an elliptic curve scheme,
so that an adversary must break both.  There is an imminent danger
that blinding operations can fail if only one of the component schemes
fails.

As an example, we consider a Sphinx-like mix net packet format that
employs the ordinary Curve25519 key exchange for blinding along side
a post-quantum scheme with any magical properties we desire.  
A quantum computer can break this by computing $b_{\alpha,\alpha'}$
such that $\alpha' = b_{\alpha,\alpha'} \alpha$ for every pair of
incoming $\alpha$ and outgoing $\alpha'$.  Any $b_{\alpha,\alpha'}$
with high bit zero cannot be correct, thus giving the adversary at
least a 50\% advantage in guessing packet routes correctly.

We can theoretically correct this by using a scalar multiplication that does not
zero the high bit in the scalar.  In doing so, we must keep the
multiplication by the cofactor so that the adversary cannot tag
packets by injecting small subgroup elements that do not impact the
key exchange itself.  These are standard moves in elliptic curve 
cryptography that work since the scalar multiplication is bijective.
To be blunt, the elliptic curve scalar multiplication can act as
a blinding operation in a hybrid protocol because the blinding itself
can be made information theoretically secure.

While this may suffice to secure a hybrid scheme against post-quantum
attacks against the Elliptic curve, we encounter a fatal difficulty
if we imagine that our post-quantum key 
exchange might be broken while elliptic curves remains secure.  
There are no known blinding operations that provide information
theoretic security, so attacks on the post-quantum component must be
expected to yield an advantage in guessing packet routes.


\subsection{Hybrid schemes using separate keys}

We could build a hybrid protocol if our post-quantum key exchange
used a separate keys for each hop instead of blinding.  These keys
could be packaged into $\beta$ along with the routing directions and
MACs for Sphinx, but doing so makes the total size of post-quantum 
key material quadratic in the number of hops, and these post-quantum
keys are already extremely large.
% FIXME: again, how do you get to quadratic!?!?!?!?
In this vein, a circuit based approach like Tor at least avoids
transmitting unnecessary key material, but it exposes circuit
metadata by doing so. 
Instead, we draw inspiration from the Axolotl
ratchet~\cite{TextSecure}, and fs-mixes~\cite{fs-mix}.\footnote{In
  fact, we developed Xolotl without knowing about fs-mixes but the
  comparison clearly simplifies the exposition.}

\subsubsection{fs-mixes}
% fs-mixes refresher
% FIXME: combined text that was previously spread all over
% the document here, but needs editing ...

fs-mixes~\cite{fs-mix} provide an approach that
avoids imposing constraints on the public key exchange.  In fs-mixes,
a mix node derives a $(k,v)$ from from each key exchange and records
$(k,v)$ in a name-value store.  We already do something similar for 
replay protection, but this new name-value store outlives our public
key rotation schedule.  A subsequent packet sent in another public
key epoch may ask that $v$ be hashed into the key exchange after
revealing its name $k$.  

These fs-mixes could be viewed as a form of ``ratchet'' not wholly
unlike off-the-record (OtR) messaging ratchet~\cite{OtR},
sometimes described as a three-step Diffie-Hellman ratchet.  
We shall extend fs-mixes to provide stronger protection and be more
reliable.  Intuitively this parallels how the Axolotl 
ratchet extends OtR with a hash iteration ratchet.

In fs-mixes, every packet leaves a trace of symmetric
key materials $v$ that {\it one} later packet can reference with its
name $k$.  In principle, we could chain these traces similarly to
how off-the-record messaging \cite{OtR} chains key exchanges.
In fact, we could buy ourselves a measure of post-quantum protections
through chaining if our initial trace pairs $(k,v)$ were created with
a post-quantum key exchange.  Yet, we cannot employ chaining with
fs-mixes directly because doing so magnifies any unreliability in
our mix network. 

\subsubsection{Axolotl}
% Axolotl refresher
\def\ck{\texttt{ck}}
\def\rk{\texttt{rk}}
\def\mk{\texttt{mk}}

The Axolotl ratchet~\cite{TextSecure} replaces the off-the-record
messaging ratchet's three-step process with a two-step procedure
that omits advertising a new key update.  Instead, Axolotl continues
using the same public key $A = a G$ in each packet until witnessing
the other side change their key $B = b G$.  Then, Axolotl does the DH key
exchange between the sender's new public key $A$ and the receiver's
public key $B$ that was last seen by the sender.

As in OtR, there is a {\it root key} $\rk$ that Axolotl advances by
hashing it with the results of the DH key exchange.  Axolotl avoids using the same key for
repeated encryptions when the receiver remains silent by deriving the
{\it chain key} $\ck_i$ for a hash iteration ratchet from the root key.

\[ \begin{aligned}
\textrm{root advance}\quad
r' &:= H(r \,||\, a B) = H(r \,||\, b A) \\ % \mathcomma
\textrm{chain start}\quad
 \ck_0 &:= H(\textrm{``Start''} \,||\, \rk) \\
\textrm{chain advance}\quad
 \ck_{i+1} &:= H(\textrm{``Chain''} \,||\, \ck_i)  \\
\textrm{message keys}\quad
 \mk_{j+1} &:= H(\textrm{``Message''} \,||\, \ck_i)  \\
\end{aligned} \]

These ratchet constructions like Axolotl and OtR remain secure against
Shor's algorithm {\it if} the root key is first instantiated with some
post-quantum key exchange, and is twice the desired security level. 
In this case, the ratchet does not provide any post-quantum forward
security per se, but that might be perfectly acceptable given current
obstacles to building quantum computers, and the large key sizes of
some post-quantum key exchanges. 


Axolotl meshes poorly with the mix networks for two key reasons:
\begin{enumerate}
 \item
 We would prefer to exploit the elliptic curve point
 already in the Sphinx header, which must change with each packet
 to avoid correlation attacks; 
 however, Axolotl must hold its key constant until receiving a response.
 \item
 We cannot make mix nodes to respond to the sender, as that
 be comes an onion routing like scheme and the additional traffic
 would make it much more vulnerable to traffic analysis.
\end{enumerate}


\section{The Xolotl ratchet}
% NOTE: CG has not yet really gone over this section.

\def\cn{\texttt{cn}}
\def\DH{\texttt{DH}}
\def\lk{\texttt{lk}}
\def\sk{\texttt{sk}}
\def\ECDH{\textrm{ECDH}}

We resolve these tensions by ``swapping the order'' of the hash
iteration ratchet and the two-step Diffie-Hellman ratchet that make
up Axolotl.   
%
We have not root key per se in Xolotl.  
Instead, we have only a hash iteration ratchet, called a branch,
consisting of a {\it chain key} $\ck_j$ representing the head of the
ratchet and {\it link keys} $\lk_j$, which Axolotl called a message
key.  We hash this link key $\lk_j$ with the shared secret $s_i$
derived from the key exchange in Sphinx to produce both an improved
shared secret $t_j$ for another layer of Sphinx and a {\it berry key} $r_j$. 
These berry keys act like the root key in Axolotl because if the
client determines the message passed through the network successfully
then it could spawn a new hash iteration ratchet.

We address a branch with a mid-evil naming convention: 
A branch's own proper name has the form $(f,b)$ where
 $f$ is its family name determined by its parent branch, and
 $b$ is the index of the berry from which it grew.
In essence, we address the branch as ``5th child of George'',
or $(f,b)$, because everybody already knows the great deeds
of the branch's parent ``George'', or $f$ or short. 
There is however a family name $f'$ defined by $(f,b)$ so that
once $(f,b)$ has performed their own great deeds then their
children may be addressed as $(f',\cdot)$.

\smallskip \noindent {\bf Xolotl ratchet description :} 

A node begins as if decoding a typical Sphinx packet by
 producing the shared secret $s_i$, verifying the MAC, and 
 unwrapping one layer of the header's onion encrypted $\beta$,
producing a $\beta'$,
but then pauses to check for a ratchet flag. 
If not found, then our node continues with Sphinx as usual.
In particular, it takes $\beta_{i+1}$ to be $\beta'$,
derives the blinding factor $b_i$,
blinds the public key as $\alpha_{i+1} := b_i \alpha_i$,
extracts the next hop $n_{i+1}$ and MAC $\gamma_{i+1}$,
unwraps an onion layer from the body $\delta_i$,
 yielding $\delta_{i+1}$, and queues the new packet
$(\alpha_{i+1},\gamma_{i+1},\beta_{i+1},\delta_{i+1})$ for $n_{i+1}$.

If found, then we extract the ratchet instructions instead.
These ratchet instructions consist of a branch address,
which contains a branch family name $f$ and a berry index $b$,
 as well as a chain index $j'$,
along with an intermediate MAC $\gamma'$.
% perhaps along with information for closing the previous chain. 

If the branch $(f,b)$ is unknown, then we locate its parent's
proper name $(f_0,b_0)$ using $f$ alone, and extract the berry
key $r$ with berry index $b$ on $(f_0,b_0)$,
 aborting if it does not exist.
From $r$, we define
\[ \begin{aligned}
\textrm{family name}\quad
 f' &:= H(\textrm{``Family''} \,||\, r) \quad\textrm{and} \\ % \mathcomma \\
\textrm{chain start}\quad
 \ck_0 &:= H(\textrm{``Start''} \,||\, r) \mathperiod \\
\end{aligned} \]
On our branch $(f,b)$, we inductively define 
\[ \begin{aligned}
\textrm{chain keys}\quad
 \ck_{j+1} &:= H(\textrm{``Chain''} \,||\, \ck_j) \quad\textrm{and} \\ % \mathcomma \\
\textrm{link keys}\quad
 \lk_j &:= H(\textrm{``Link''} \,||\, \ck_j) \mathperiod \\
\end{aligned} \]
In advancing the chain to index $j'$, we naturally save any 
intermediate $\lk_j$ for later use by out of sequence packets.

We now have the particular $\lk_{j'}$ requested by our ratchet 
instructions $(f,b,j')$, so we may define 
\[ \begin{aligned}
\textrm{packet keys}\quad 
 s' &:= H(\lk_j \,||\, s_i) \quad\textrm{and} \\ % \mathcomma \\
\textrm{berry keys}\quad 
 r' &:= H(\textrm{``Berry''} \,||\, s') \mathperiod \\
\end{aligned} \]
We first replace $s_i$ by $s'$ in our Sphinx-like component
and verify the intermediate MAC $\gamma'$.  If this verification
fails, then we abort and abandon our ratchet database transaction.
We thus assume the verification succeeds.  

We now save $r'$ as the berry key for $(f,b,j')$, and commit any
other ratchet database changes, including erasing $r$ or any 
$\ck_i$ previously recorded.  Our branch $(f,b)$ has started
earning the short name its children will use.  
Also, our Sphinx-like component continues, but now using $s'$.
To be specific, it derives the blinding factor $b_i$,
blinds the public key as $\alpha_{i+1} = b_i \alpha_i$,
unwraps a second layer of $\beta$ to extracts the
 next hop $n_{i+1}$ and MAC $\gamma_{i+1}$ and 
 producing our $\beta_{i+1}$,
unwraps an onion layer from the body $\delta_i$,
 yielding $\delta_{i+1}$, and queues the new packet
$(\alpha_{i+1},\gamma_{i+1},\beta_{i+1},\delta_{i+1})$ for $n_{i+1}$.

 \begin{figure}[b!]%[h!]
   \begin{center}
\begin{tikzcd}[ampersand replacement=\&, column sep=small]
\cdot \ar[r] \& \cdot \ar[r] \ar[d] \& \cdot \ar[r] \ar[d] \& \cdot \ar[r] \ar[d] \& \ck \ar[r, dotted] \& ? \& \\
 \& \lk \ar[d] \& \lk \ar[d]  \& \lk \ar[d] \&  \& \& \\ 
 \& \ECDH \ar[d] \& \ECDH \ar[d] \& \ECDH\ar[d] \&  \& \& \\
 \& r \& r \ar[dddll, in=90, out=270] \& r \ar[dddlll, dotted, in=30, out=270] \&  \& \& \\
\\
\\
\cdot \ar[r] \& \cdot \ar[r] \ar[d] \& \cdot \ar[r] \ar[d] \& \cdot \ar[r] \ar[d] \& \cdot \ar[r] \ar[d] \& \ck \& \& \\
 \& \lk \ar[d] \& \lk \ar[d] \& \lk \ar[d, dotted] \& \lk \ar[d] \&  \& \& \\ 
 \& \ECDH \ar[d] \& \ECDH \ar[d] \& ? \& \ECDH\ar[d] \&  \& \& \\
 \& r \& r \&  \& r \&  \& \& \\
\end{tikzcd}
% FIXME: ECDH should probably be SPHINX+? 
\end{center}
\end{figure}


\subsection{Faster chains}

We have described a simple linear hash iteration ratchet above.  
These work well in Axolotl because the sender controls the desired
order of delivery and the transport makes some effort to comply.

In Xolotl, we envision using ratchets when receiving a message 
using a single-use reply blocks (SURBs), as well as when sending.
We should expect SURBs to be used in a far more haphazard way or
indeed discarded when node keys rotate.  

Axolotl also benefits from being used between established contacts,
while mix nodes would provide Xolotl ratchets as a service, like
for free.  We therefore worry malicious clients might ask mix nodes
to forward ratchets for extreme distances as a denial of service
attack, while the mix node cannot easily distinguish this malicious
behavior from poor SURB usage.

We address these concerns by optimizing our procedure for advancing
the chain key.  We reserve the low $l$ bits of the chain index
for a chain key that works as described above.  
If our index $j$ has a nonzero bit among its lower $l$ bits,
meaning $j \& (2^l-1) \neq 0$, then
we define
\[ \begin{aligned}
 \ck_{j+1} &:= H(\textrm{``Chain''} \,||\, \ck_j) \quad\textrm{and} \\ % \mathcomma \\
\end{aligned} \]
We reserve bit $l$ and higher for a faster tree-like {\it train key}
built using heap addressing.  If the lower $l$ bits of $j$ are
all zero, meaning $j \& (2^l-1) \neq 0$, then we define 
\[ \begin{aligned}
% \textrm{train left}\quad
 \ck_{2j} &:= H(\textrm{``Left''} \,||\, \ck_j) \mathcomma \\
% \textrm{train right}\quad
 \ck_{2j+2^l} &:= H(\textrm{``Right''} \,||\, \ck_j) \mathcomma \\
% \textrm{chain key}\quad
 \ck_{j+1} &:= H(\textrm{``Chain''} \,||\, \ck_j) \quad\textrm{and} \\
\end{aligned} \]
In both case, we could define the link key $\lk_j$ as before, but
the actual key derivations functions could differ between these two
cases, and doing so appears more efficient.


\subsection{Analysis}

We take $r$ to be 256 bits so that, assuming the initial ratchet
source was created using a post-quantum key exchange, then our
Xolotl ratchet provides 128 bits of post-quantum security.

In addition, Xolotl provides a measure of forward secrecy against
a classical adversary in that the symmetric key information $r$,
$\ck_j$ for $j<j'$, $\lk_{j'}$, and $s'$ all gets erased when
the packet gets queued.  An adversary who later compromises the
private key of our node $n_i$ learns the next hop only for packets
that did not employ any ratchet at $n_i$.

For these advantages, we have exposed,
 to the node $n_i$ hosting the ratchet, that all packets using this
particular ratchet were directed by the same party, making that
party either the sender or receiver if the packet is a SURB.

We expect Xolotl ratchets to be more reliable than fs-mixes because
the hash iteration ratchet component permits ratchet reuse even when
packets get dropped or delayed.  There is a corresponding cost in
that we reveal a connection between far more packets to the node
$n_i$ hosting the ratchet.

There is no need for every hop to employ a ratchet, % though, 
but specific usage patterns require detailed analysis.

\[ \begin{aligned}
\textrm{User} \to &\textrm{Tor} \to \textrm{Xolotl} \to \textrm{Sphinx} \to \\
\quad &\to \textrm{Xolotl} \to \textrm{Sphinx} \to \textrm{Cross} \to \cdots 
\end{aligned} \]

If ratchets are used at only certain hops, then the mix learns
information about its role and position in the route.  
We could mitigate this by consolidating ratchets on specified mix
nodes, presumably with more storage and/or hardened hosting, but
this doing so concentrates our forward secrecy and post-quantum 
defenses as well.

In Tor, there is a more restrictive procedure for selecting the
first hop in a circuit, called a {\it guard} node.  We expect
mix networks will benefit from specialized guard selection as well.
Assuming mix nodes can easily distinguish clients from mix nodes,
there is no need for a ratchet at guard node because the client and
the mix node should use a conventional ephemeral key exchange,
likely a hybrid of an elliptic curve and post-quantum key exchange.

An initial set of ``guard'' ratchets could be created anew for each
session, possibly distinct from the client's actual guard nodes.

We believe that retaining middle ratchets for longer periods could
improve forward secrecy over creating them all anew with each session. 
There are many concerns around this point however, primarily balancing
the improved forward secrecy with the risk of linking packets across
different sessions, but also
 practical matters like ratchet storage requirements on mix nodes.  

Ratchet key material does not expire with node keys.  Indeed, even
berry keys may outlive node keys because the sender simply remembers
them.  We may therefore set ratchet key expiration based upon storage
concerns. 


\section{Implementation}

Explain:

Xolotl in Rust.
Lake for storage and messaging.
pEp for migration.

\begin{figure}
\begin{center}
\begin{tabular}{|c|c|c|} \hline
   MTA & IM & (sensor network protocol) \\ \hline
   \multicolumn{3}{|c|}{{p$\equiv$p}}  \\ \hline
   & \multicolumn{2}{|c|}{{\bf Lake}}   \\ \cline{2-3}
   & \multicolumn{2}{|c|}{{\bf Xolotl}} \\ \cline{2-3}
   \raisebox{1.5ex}{SMTP} & CADET~\cite{cadet} & GNU Name System~\cite{gns}  \\ \cline{2-3}
   & \multicolumn{2}{|c|}{GNUnet-CORE}  \\ \hline
   \multicolumn{3}{|c|}{TCP/IP}       \\ \hline
   \multicolumn{3}{|c|}{Ethernet}     \\ \hline
\end{tabular}
\end{center}
\caption{A plan for replacing IMAP/SMTP with a few extra layers.}
\label{fig:layers}
\end{figure}


\section{Performance evaluation}

Using Bloom filter, how much storage per message?
Give resulting key rotation frequencies for realistic
scenarios. (all calculated)

Bandwidth overhead (ok to do mathematically, but precise,
in bytes).  Computational overhead (measured).

Expected latency by pool strategy. (simulated or calculated)

Messages per second on realistic hardware. (calculated from
microbenchmarks is sufficient)

Required replication level for different reliability assumptions.
Assume different reliabilities for ordinary mixes vs. aggregators
(aggregation points are picked based on known reliability).  How high
does availability need to be to keep replication reasonably low?
(calculated)

Total (system-wide) financial cost per message including reliability
for 99.9999\% availability under realistic assumptions about node
availability. (Assume Amazon EC2 compute node profile for availability
and cost on the one hand, and say a Raspberry Pi at home with typical
DSL-like network (un)availability with Indian-style power outages on
the other)

Discussion on use of Taler to pay for service.



\section{Improvements}

We expect that a malicious mix node hosting a Xolotl ratchet learns
that all packets using the ratchet were directed by the same party,
either the sender or receiver.  Considering the modest delay created
by mixes, this allows a weak correlation to be made between ratchet
use and the respective client being online.

A simple counter-measure would be support for a delay mode where
clients can flag messages to be artificially delayed by mixes beyond
the usual delay for mixing.  This could be used to create messages
that traverse the client's ratchet at times where they have been
offline for a while, thereby reducing the correlation between ratchet
use and the client being online.

Another mitigation strategy would be for clients
to share particular ratchet configurations with other nodes.
If several link keys from the same branch can be shared anonymously,
then the sharer risks nothing in doing so, assuming pre-image
resistance for our hash function.  Thus, another way of destroying the
link between ratched use and user being online would be to share a
batch of link keys from the same branch with a mix node so that it
could utilize our ratchet for messages it needed to send anyways.
However, this assumes mix nodes send numerous messages over the mix
network, which our design currently does not require.

We observe that anyone using this shared link key could gain a berry
key that only they know, along with the mix node hosting the ratchet,
thus allowing them to create a whole new branch.  It follows that,
if individual shared link keys can be retrieved anonymously, then
the recipient of the shared link key risks only that the key fails.
Thus, this creates a minor problem in the form of denial of service
attack against the receiver of such a shared ratched.

In practice, we cannot provide perfect anonymity in either sharing or
retrieving shared link keys, and retrieving lone link keys sounds
problematic.  Yet, there may be an opportunity here for a second
anonymity system that communicates these shared link keys.
% FIXME: not sure I understand ``lone link keys'' here.


\section*{Acknowledgements}

This work benefits from the financial support of the Brittany Region
(ARED 9178) and a grant from the Renewable Freedom Foundation.
% FIXME: Do you have productive discussions to acknowledge, i.e.
% with George or other pandemix people?

%\newpage

\bibliographystyle{abbrv}
\bibliography{mix,nonmix,or,msg,pq,rlwe,sidh}

\end{document}


\section{}







Anonymous messaging proposals have traditionally either avoided
request-and-forward facilities, due to metadata leakage \cite{??},
or addressed it using private information retrieval (PIR) schemes
\cite{??}.  These PIR schemes increase complexity, invoke disparate
security analysis techniques, and still leak considerable metadata.




